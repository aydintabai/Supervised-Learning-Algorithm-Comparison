{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af24e81c-8239-43ed-b3d3-47078c635173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ucimlrepo in ./.local/lib/python3.11/site-packages (0.0.7)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from ucimlrepo) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in /opt/conda/lib/python3.11/site-packages (from ucimlrepo) (2024.8.30)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91cd2f1f-ce04-4b20-88e0-c58947af3b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 850, 'name': 'Raisin', 'repository_url': 'https://archive.ics.uci.edu/dataset/850/raisin', 'data_url': 'https://archive.ics.uci.edu/static/public/850/data.csv', 'abstract': 'Images of the Kecimen and Besni raisin varieties were obtained with CVS. A total of 900 raisins were used, including 450 from both varieties, and 7 morphological features were extracted.', 'area': 'Biology', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 900, 'num_features': 7, 'feature_types': ['Real', 'Integer'], 'demographics': [], 'target_col': ['Class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2020, 'last_updated': 'Fri Jan 05 2024', 'dataset_doi': '10.24432/C5660T', 'creators': ['İ̇lkay Çinar', 'Murat Koklu', 'Sakir Tasdemir'], 'intro_paper': {'ID': 261, 'type': 'NATIVE', 'title': 'Kuru Üzüm Tanelerinin Makine Görüşü ve Yapay Zeka Yöntemleri Kullanılarak Sınıflandırılması', 'authors': 'İ̇lkay Çinar, Murat Koklu, Sakir Tasdemir', 'venue': 'Gazi Journal of Engineering Sciences', 'year': 2020, 'journal': None, 'DOI': None, 'URL': 'https://www.semanticscholar.org/paper/6e67a463c29bde6a78ead7a10508674e693b74f3', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'Images of Kecimen and Besni raisin varieties grown in Turkey were obtained with CVS. A total of 900 raisin grains were used, including 450 pieces from both varieties. These images were subjected to various stages of pre-processing and 7 morphological features were extracted. These features have been classified using three different artificial intelligence techniques.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '1.) Area: Gives the number of pixels within the boundaries of the raisin.\\n2.) Perimeter: It measures the environment by calculating the distance between the boundaries of the raisin and the pixels around it.\\n3.) MajorAxisLength: Gives the length of the main axis, which is the longest line that can be drawn on the raisin.\\n4.) MinorAxisLength: Gives the length of the small axis, which is the shortest line that can be drawn on the raisin.\\n5.) Eccentricity: It gives a measure of the eccentricity of the ellipse, which has the same moments as raisins.\\n6.) ConvexArea: Gives the number of pixels of the smallest convex shell of the region formed by the raisin.\\n7.) Extent: Gives the ratio of the region formed by the raisin to the total pixels in the bounding box.\\n8.) Class: Kecimen and Besni raisin.', 'citation': 'CINAR I., KOKLU M. and TASDEMIR S., (2020), Classification of Raisin Grains Using Machine Vision and Artificial Intelligence Methods. Gazi Journal of Engineering Sciences, vol. 6, no. 3, pp. 200-209, December, 2020. '}}\n",
      "              name     role         type demographic  \\\n",
      "0             Area  Feature      Integer        None   \n",
      "1  MajorAxisLength  Feature   Continuous        None   \n",
      "2  MinorAxisLength  Feature   Continuous        None   \n",
      "3     Eccentricity  Feature   Continuous        None   \n",
      "4       ConvexArea  Feature      Integer        None   \n",
      "5           Extent  Feature   Continuous        None   \n",
      "6        Perimeter  Feature   Continuous        None   \n",
      "7            Class   Target  Categorical        None   \n",
      "\n",
      "                                         description units missing_values  \n",
      "0  Gives the number of pixels within the boundari...  None             no  \n",
      "1  It measures the environment by calculating the...  None             no  \n",
      "2  Gives the length of the main axis, which is th...  None             no  \n",
      "3  Gives the length of the small axis, which is t...  None             no  \n",
      "4  It gives a measure of the eccentricity of the ...  None             no  \n",
      "5  Gives the number of pixels of the smallest con...  None             no  \n",
      "6  Gives the ratio of the region formed by the ra...  None             no  \n",
      "7                          Kecimen and Besni raisin.  None             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "raisin = fetch_ucirepo(id=850) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = raisin.data.features \n",
    "y = raisin.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(raisin.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(raisin.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dd2dd40-1a42-4699-b428-2c680c03fe1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Area  MajorAxisLength  MinorAxisLength  Eccentricity  ConvexArea  \\\n",
      "0  87524       442.246011       253.291155      0.819738       90546   \n",
      "1  75166       406.690687       243.032436      0.801805       78789   \n",
      "2  90856       442.267048       266.328318      0.798354       93717   \n",
      "3  45928       286.540559       208.760042      0.684989       47336   \n",
      "4  79408       352.190770       290.827533      0.564011       81463   \n",
      "\n",
      "     Extent  Perimeter  \n",
      "0  0.758651   1184.040  \n",
      "1  0.684130   1121.786  \n",
      "2  0.637613   1208.575  \n",
      "3  0.699599    844.162  \n",
      "4  0.792772   1073.251  \n",
      "     Class\n",
      "0  Kecimen\n",
      "1  Kecimen\n",
      "2  Kecimen\n",
      "3  Kecimen\n",
      "4  Kecimen\n",
      "Area               0\n",
      "MajorAxisLength    0\n",
      "MinorAxisLength    0\n",
      "Eccentricity       0\n",
      "ConvexArea         0\n",
      "Extent             0\n",
      "Perimeter          0\n",
      "dtype: int64\n",
      "Class  \n",
      "Besni      450\n",
      "Kecimen    450\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X.head())\n",
    "print(y.head())\n",
    "\n",
    "print(X.isnull().sum())\n",
    "\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6c15ade-ec79-4e5c-b9c3-b8cff8536ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "y_encoded = LabelEncoder().fit_transform(y.values.ravel())\n",
    "\n",
    "splits = {\n",
    "    \"20/80\": train_test_split(X, y_encoded, train_size=0.2, random_state=42, stratify=y_encoded),\n",
    "    \"50/50\": train_test_split(X, y_encoded, train_size=0.5, random_state=42, stratify=y_encoded),\n",
    "    \"80/20\": train_test_split(X, y_encoded, train_size=0.8, random_state=42, stratify=y_encoded)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56e113cc-122f-45c4-829b-953dec1dbcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def tune_hyperparameters(X_train, y_train, X_train_scaled, clf_name):\n",
    "    if clf_name == \"Random Forest\":\n",
    "        param_grid = {\"max_depth\": [10, 20, 30]}\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "    elif clf_name == \"SVM\":\n",
    "        param_grid = {\"C\": [0.1, 1, 10, 100]}\n",
    "        model = SVC(kernel=\"rbf\", random_state=42)\n",
    "    elif clf_name == \"Logistic Regression\":\n",
    "        param_grid = {\"C\": [0.1, 1, 10, 100]}\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "    grid = GridSearchCV(model, param_grid, cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
    "    grid.fit(X_train_scaled if clf_name in [\"SVM\", \"Logistic Regression\"] else X_train, y_train)\n",
    "    return grid.best_params_\n",
    "\n",
    "best_params = {}\n",
    "\n",
    "for split_name, (X_train, X_test, y_train, y_test) in splits.items():\n",
    "    X_train_scaled = StandardScaler().fit_transform(X_train)\n",
    "\n",
    "    best_params[split_name] = {\n",
    "        \"Random Forest\": tune_hyperparameters(X_train, y_train, X_train_scaled, \"Random Forest\"),\n",
    "        \"SVM\": tune_hyperparameters(X_train, y_train, X_train_scaled, \"SVM\"),\n",
    "        \"Logistic Regression\": tune_hyperparameters(X_train, y_train, X_train_scaled, \"Logistic Regression\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a83e3ce-1f7f-433d-bd1e-8238d024ff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "train_acc = {}\n",
    "val_acc = {}\n",
    "test_acc = {}\n",
    "\n",
    "for split_name, (X_train, X_test, y_train, y_test) in splits.items():\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    rf_params = best_params[split_name][\"Random Forest\"]\n",
    "    svm_params = best_params[split_name][\"SVM\"]\n",
    "    lr_params = best_params[split_name][\"Logistic Regression\"]\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=42, **rf_params)\n",
    "    svm = SVC(random_state=42, **svm_params)\n",
    "    lr = LogisticRegression(random_state=42, max_iter=1000, **lr_params)\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    svm.fit(X_train_scaled, y_train)\n",
    "    lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "    rf_val_acc = cross_val_score(rf, X_train, y_train, cv=3, scoring=\"accuracy\").mean()\n",
    "    svm_val_acc = cross_val_score(svm, X_train_scaled, y_train, cv=3, scoring=\"accuracy\").mean()\n",
    "    lr_val_acc = cross_val_score(lr, X_train_scaled, y_train, cv=3, scoring=\"accuracy\").mean()\n",
    "\n",
    "    train_acc[split_name] = {\n",
    "        \"Random Forest\": accuracy_score(y_train, rf.predict(X_train)),\n",
    "        \"SVM\": accuracy_score(y_train, svm.predict(X_train_scaled)),\n",
    "        \"Logistic Regression\": accuracy_score(y_train, lr.predict(X_train_scaled)),\n",
    "    }\n",
    "\n",
    "    val_acc[split_name] = {\n",
    "        \"Random Forest\": rf_val_acc,\n",
    "        \"SVM\": svm_val_acc,\n",
    "        \"Logistic Regression\": lr_val_acc,\n",
    "    }\n",
    "\n",
    "    test_acc[split_name] = {\n",
    "        \"Random Forest\": accuracy_score(y_test, rf.predict(X_test)),\n",
    "        \"SVM\": accuracy_score(y_test, svm.predict(X_test_scaled)),\n",
    "        \"Logistic Regression\": accuracy_score(y_test, lr.predict(X_test_scaled)),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f694340-977c-4d16-93a7-f30434d0848b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Classifier Train/Test  Training Accuracy  Validation Accuracy  \\\n",
      "0        Random Forest      20/80           1.000000             0.838889   \n",
      "1                  SVM      20/80           0.866667             0.866667   \n",
      "2  Logistic Regression      20/80           0.877778             0.877778   \n",
      "3        Random Forest      50/50           0.997778             0.873333   \n",
      "4                  SVM      50/50           0.886667             0.880000   \n",
      "5  Logistic Regression      50/50           0.882222             0.871111   \n",
      "6        Random Forest      80/20           1.000000             0.852778   \n",
      "7                  SVM      80/20           0.869444             0.865278   \n",
      "8  Logistic Regression      80/20           0.862500             0.866667   \n",
      "\n",
      "   Testing Accuracy Best Hyperparameter  \n",
      "0          0.845833   {'max_depth': 10}  \n",
      "1          0.856944            {'C': 1}  \n",
      "2          0.863889          {'C': 100}  \n",
      "3          0.831111   {'max_depth': 10}  \n",
      "4          0.848889          {'C': 0.1}  \n",
      "5          0.853333          {'C': 0.1}  \n",
      "6          0.866667   {'max_depth': 20}  \n",
      "7          0.872222          {'C': 0.1}  \n",
      "8          0.888889          {'C': 100}  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "\n",
    "for split_name in splits.keys():\n",
    "    for clf_name in [\"Random Forest\", \"SVM\", \"Logistic Regression\"]:\n",
    "        results.append({\n",
    "            \"Classifier\": clf_name,\n",
    "            \"Train/Test\": split_name,\n",
    "            \"Training Accuracy\": train_acc[split_name][clf_name],\n",
    "            \"Validation Accuracy\": val_acc[split_name][clf_name],\n",
    "            \"Testing Accuracy\": test_acc[split_name][clf_name],\n",
    "            \"Best Hyperparameter\": best_params[split_name][clf_name]\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c39c6adc-57d6-4755-ab4e-d0de0f33cf5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 529, 'name': 'Early Stage Diabetes Risk Prediction', 'repository_url': 'https://archive.ics.uci.edu/dataset/529/early+stage+diabetes+risk+prediction+dataset', 'data_url': 'https://archive.ics.uci.edu/static/public/529/data.csv', 'abstract': 'This dataset contains the sign and symptpom data of newly diabetic or would be diabetic patient. ', 'area': 'Computer Science', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 520, 'num_features': 16, 'feature_types': ['Categorical', 'Integer'], 'demographics': ['Age', 'Gender'], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2020, 'last_updated': 'Mon Mar 04 2024', 'dataset_doi': '10.24432/C5VG8H', 'creators': [], 'intro_paper': {'ID': 397, 'type': 'NATIVE', 'title': 'Likelihood Prediction of Diabetes at Early Stage Using Data Mining Techniques', 'authors': 'M. M. F. Islam, Rahatara Ferdousi, Sadikur Rahman, Humayra Yasmin Bushra', 'venue': 'Computer Vision and Machine Intelligence in Medical Image Analysis', 'year': 2019, 'journal': None, 'DOI': '10.1007/978-981-13-8798-2_12', 'URL': 'https://www.semanticscholar.org/paper/9329dec57c5f13f195220ffa7077fd0029983f07', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'This has been col-\\r\\nlected using direct questionnaires from the patients of Sylhet Diabetes\\r\\nHospital in Sylhet, Bangladesh and approved by a doctor.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Age 1.20-65\\t\\t\\r\\nSex 1. Male, 2.Female\\t\\t\\r\\nPolyuria 1.Yes, 2.No.\\t\\t\\r\\nPolydipsia 1.Yes, 2.No.\\t\\t\\r\\nsudden weight loss 1.Yes, 2.No.\\t\\t\\r\\nweakness 1.Yes, 2.No.\\t\\t\\r\\nPolyphagia 1.Yes, 2.No.\\t\\t\\r\\nGenital thrush 1.Yes, 2.No.\\t\\t\\r\\nvisual blurring 1.Yes, 2.No.\\t\\t\\r\\nItching 1.Yes, 2.No.\\t\\t\\r\\nIrritability 1.Yes, 2.No.\\t\\t\\r\\ndelayed healing 1.Yes, 2.No.\\t\\t\\r\\npartial paresis 1.Yes, 2.No.\\t\\t\\r\\nmuscle sti\\x0bness 1.Yes, 2.No.\\t\\t\\r\\nAlopecia 1.Yes, 2.No.\\t\\t\\r\\nObesity 1.Yes, 2.No.\\t\\t\\r\\nClass 1.Positive, 2.Negative.\\t\\t\\r\\n', 'citation': None}}\n",
      "                  name     role         type demographic description units  \\\n",
      "0                  age  Feature      Integer         Age        None  None   \n",
      "1               gender  Feature  Categorical      Gender        None  None   \n",
      "2             polyuria  Feature       Binary        None        None  None   \n",
      "3           polydipsia  Feature       Binary        None        None  None   \n",
      "4   sudden_weight_loss  Feature       Binary        None        None  None   \n",
      "5             weakness  Feature       Binary        None        None  None   \n",
      "6           polyphagia  Feature       Binary        None        None  None   \n",
      "7       genital_thrush  Feature       Binary        None        None  None   \n",
      "8      visual_blurring  Feature       Binary        None        None  None   \n",
      "9              itching  Feature       Binary        None        None  None   \n",
      "10        irritability  Feature       Binary        None        None  None   \n",
      "11     delayed_healing  Feature       Binary        None        None  None   \n",
      "12     partial_paresis  Feature       Binary        None        None  None   \n",
      "13    muscle_stiffness  Feature       Binary        None        None  None   \n",
      "14            alopecia  Feature       Binary        None        None  None   \n",
      "15             obesity  Feature       Binary        None        None  None   \n",
      "16               class   Target       Binary        None        None  None   \n",
      "\n",
      "   missing_values  \n",
      "0              no  \n",
      "1              no  \n",
      "2              no  \n",
      "3              no  \n",
      "4              no  \n",
      "5              no  \n",
      "6              no  \n",
      "7              no  \n",
      "8              no  \n",
      "9              no  \n",
      "10             no  \n",
      "11             no  \n",
      "12             no  \n",
      "13             no  \n",
      "14             no  \n",
      "15             no  \n",
      "16             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "early_stage_diabetes_risk_prediction = fetch_ucirepo(id=529) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X_1 = early_stage_diabetes_risk_prediction.data.features \n",
    "y_1 = early_stage_diabetes_risk_prediction.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(early_stage_diabetes_risk_prediction.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(early_stage_diabetes_risk_prediction.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5657f20c-213c-40c8-a9f3-d90fc1fec3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age gender polyuria polydipsia sudden_weight_loss weakness polyphagia  \\\n",
      "0   40   Male       No        Yes                 No      Yes         No   \n",
      "1   58   Male       No         No                 No      Yes         No   \n",
      "2   41   Male      Yes         No                 No      Yes        Yes   \n",
      "3   45   Male       No         No                Yes      Yes        Yes   \n",
      "4   60   Male      Yes        Yes                Yes      Yes        Yes   \n",
      "\n",
      "  genital_thrush visual_blurring itching irritability delayed_healing  \\\n",
      "0             No              No     Yes           No             Yes   \n",
      "1             No             Yes      No           No              No   \n",
      "2             No              No     Yes           No             Yes   \n",
      "3            Yes              No     Yes           No             Yes   \n",
      "4             No             Yes     Yes          Yes             Yes   \n",
      "\n",
      "  partial_paresis muscle_stiffness alopecia obesity  \n",
      "0              No              Yes      Yes     Yes  \n",
      "1             Yes               No      Yes      No  \n",
      "2              No              Yes      Yes      No  \n",
      "3              No               No       No      No  \n",
      "4             Yes              Yes      Yes     Yes  \n",
      "      class\n",
      "0  Positive\n",
      "1  Positive\n",
      "2  Positive\n",
      "3  Positive\n",
      "4  Positive\n"
     ]
    }
   ],
   "source": [
    "print(X_1.head())\n",
    "print(y_1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e17f96d7-495f-4d1e-9308-3160267968b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1_encoded = LabelEncoder().fit_transform(y_1.values.ravel())\n",
    "\n",
    "X_1_encoded = X_1.copy()\n",
    "for col in X_1.columns:\n",
    "    if X_1[col].dtype == 'object':\n",
    "        X_1_encoded[col] = LabelEncoder().fit_transform(X_1[col])\n",
    "\n",
    "X_1_scaled = StandardScaler().fit_transform(X_1_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c061436d-5ab1-4fbe-b560-3e58ee8e0c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_1 = {\n",
    "    \"20/80\": train_test_split(X_1_scaled, y_1_encoded, train_size=0.2, random_state=42, stratify=y_1_encoded),\n",
    "    \"50/50\": train_test_split(X_1_scaled, y_1_encoded, train_size=0.5, random_state=42, stratify=y_1_encoded),\n",
    "    \"80/20\": train_test_split(X_1_scaled, y_1_encoded, train_size=0.8, random_state=42, stratify=y_1_encoded)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcfc4fea-6cd6-41c4-b2e6-16f5de9b73ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_hyperparameters(X_train, y_train, clf_name):\n",
    "    if clf_name == \"Random Forest\":\n",
    "        param_grid = {\"max_depth\": [10, 20, 30]}\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "    elif clf_name == \"SVM\":\n",
    "        param_grid = {\"C\": [0.1, 1, 10, 100]}\n",
    "        model = SVC(kernel=\"rbf\", random_state=42)\n",
    "    elif clf_name == \"Logistic Regression\":\n",
    "        param_grid = {\"C\": [0.1, 1, 10, 100]}\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "    grid = GridSearchCV(model, param_grid, cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    return grid.best_params_\n",
    "\n",
    "best_params_1 = {}\n",
    "\n",
    "for split_name, (X_train, X_test, y_train, y_test) in splits_1.items():\n",
    "    best_params_1[split_name] = {\n",
    "        \"Random Forest\": tune_hyperparameters(X_train, y_train, \"Random Forest\"),\n",
    "        \"SVM\": tune_hyperparameters(X_train, y_train, \"SVM\"),\n",
    "        \"Logistic Regression\": tune_hyperparameters(X_train, y_train, \"Logistic Regression\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00414bd4-5c54-4ad2-970b-f8ba0762cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_1 = {}\n",
    "val_acc_1 = {}\n",
    "test_acc_1 = {}\n",
    "\n",
    "for split_name, (X_train, X_test, y_train, y_test) in splits_1.items():\n",
    "    rf_params = best_params_1[split_name][\"Random Forest\"]\n",
    "    svm_params = best_params_1[split_name][\"SVM\"]\n",
    "    lr_params = best_params_1[split_name][\"Logistic Regression\"]\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=42, **rf_params)\n",
    "    svm = SVC(random_state=42, **svm_params)\n",
    "    lr = LogisticRegression(random_state=42, max_iter=1000, **lr_params)\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    svm.fit(X_train, y_train)\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    rf_val_acc = cross_val_score(rf, X_train, y_train, cv=3, scoring=\"accuracy\").mean()\n",
    "    svm_val_acc = cross_val_score(svm, X_train, y_train, cv=3, scoring=\"accuracy\").mean()\n",
    "    lr_val_acc = cross_val_score(lr, X_train, y_train, cv=3, scoring=\"accuracy\").mean()\n",
    "\n",
    "    train_acc_1[split_name] = {\n",
    "        \"Random Forest\": accuracy_score(y_train, rf.predict(X_train)),\n",
    "        \"SVM\": accuracy_score(y_train, svm.predict(X_train)),\n",
    "        \"Logistic Regression\": accuracy_score(y_train, lr.predict(X_train)),\n",
    "    }\n",
    "\n",
    "    val_acc_1[split_name] = {\n",
    "        \"Random Forest\": rf_val_acc,\n",
    "        \"SVM\": svm_val_acc,\n",
    "        \"Logistic Regression\": lr_val_acc,\n",
    "    }\n",
    "\n",
    "    test_acc_1[split_name] = {\n",
    "        \"Random Forest\": accuracy_score(y_test, rf.predict(X_test)),\n",
    "        \"SVM\": accuracy_score(y_test, svm.predict(X_test)),\n",
    "        \"Logistic Regression\": accuracy_score(y_test, lr.predict(X_test)),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a1f2c2d-f1ee-4082-862b-3e5c0656d2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Classifier Train/Test  Training Accuracy  Validation Accuracy  \\\n",
      "0        Random Forest      20/80           1.000000             0.893557   \n",
      "1                  SVM      20/80           0.990385             0.913165   \n",
      "2  Logistic Regression      20/80           0.942308             0.913445   \n",
      "3        Random Forest      50/50           1.000000             0.957676   \n",
      "4                  SVM      50/50           0.984615             0.946093   \n",
      "5  Logistic Regression      50/50           0.950000             0.919139   \n",
      "6        Random Forest      80/20           1.000000             0.966375   \n",
      "7                  SVM      80/20           0.995192             0.956748   \n",
      "8  Logistic Regression      80/20           0.939904             0.918257   \n",
      "\n",
      "   Testing Accuracy Best Hyperparameter  \n",
      "0          0.944712   {'max_depth': 10}  \n",
      "1          0.937500           {'C': 10}  \n",
      "2          0.889423            {'C': 1}  \n",
      "3          0.950000   {'max_depth': 10}  \n",
      "4          0.961538            {'C': 1}  \n",
      "5          0.892308           {'C': 10}  \n",
      "6          0.990385   {'max_depth': 20}  \n",
      "7          0.971154           {'C': 10}  \n",
      "8          0.942308          {'C': 100}  \n"
     ]
    }
   ],
   "source": [
    "results_1 = []\n",
    "\n",
    "for split_name in splits_1.keys():\n",
    "    for clf_name in [\"Random Forest\", \"SVM\", \"Logistic Regression\"]:\n",
    "        results_1.append({\n",
    "            \"Classifier\": clf_name,\n",
    "            \"Train/Test\": split_name,\n",
    "            \"Training Accuracy\": train_acc_1[split_name][clf_name],\n",
    "            \"Validation Accuracy\": val_acc_1[split_name][clf_name],\n",
    "            \"Testing Accuracy\": test_acc_1[split_name][clf_name],\n",
    "            \"Best Hyperparameter\": best_params_1[split_name][clf_name]\n",
    "        })\n",
    "\n",
    "results_df_1 = pd.DataFrame(results_1)\n",
    "\n",
    "print(results_df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6aae7fce-76f4-4115-84f0-64c52d5fd44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 19, 'name': 'Car Evaluation', 'repository_url': 'https://archive.ics.uci.edu/dataset/19/car+evaluation', 'data_url': 'https://archive.ics.uci.edu/static/public/19/data.csv', 'abstract': 'Derived from simple hierarchical decision model, this database may be useful for testing constructive induction and structure discovery methods.', 'area': 'Other', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 1728, 'num_features': 6, 'feature_types': ['Categorical'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1988, 'last_updated': 'Thu Aug 10 2023', 'dataset_doi': '10.24432/C5JP48', 'creators': ['Marko Bohanec'], 'intro_paper': {'ID': 249, 'type': 'NATIVE', 'title': 'Knowledge acquisition and explanation for multi-attribute decision making', 'authors': 'M. Bohanec, V. Rajkovič', 'venue': '8th Intl Workshop on Expert Systems and their Applications, Avignon, France', 'year': 1988, 'journal': None, 'DOI': None, 'URL': 'https://www.semanticscholar.org/paper/KNOWLEDGE-ACQUISITION-AND-EXPLANATION-FOR-DECISION-Bohanec-Rajkovi%C4%8D/8bab443ae322ff47c3e609272bd93fd4650555bc', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'Car Evaluation Database was derived from a simple hierarchical decision model originally developed for the demonstration of DEX, M. Bohanec, V. Rajkovic: Expert system for decision making. Sistemica 1(1), pp. 145-157, 1990.). The model evaluates cars according to the following concept structure:\\r\\n\\r\\nCAR                      car acceptability\\r\\n. PRICE                  overall price\\r\\n. . buying               buying price\\r\\n. . maint                price of the maintenance\\r\\n. TECH                   technical characteristics\\r\\n. . COMFORT              comfort\\r\\n. . . doors              number of doors\\r\\n. . . persons            capacity in terms of persons to carry\\r\\n. . . lug_boot           the size of luggage boot\\r\\n. . safety               estimated safety of the car\\r\\n\\r\\nInput attributes are printed in lowercase. Besides the target concept (CAR), the model includes three intermediate concepts: PRICE, TECH, COMFORT. Every concept is in the original model related to its lower level descendants by a set of examples (for these examples sets see http://www-ai.ijs.si/BlazZupan/car.html).\\r\\n\\r\\nThe Car Evaluation Database contains examples with the structural information removed, i.e., directly relates CAR to the six input attributes: buying, maint, doors, persons, lug_boot, safety.\\r\\n\\r\\nBecause of known underlying concept structure, this database may be particularly useful for testing constructive induction and structure discovery methods.\\r\\n', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'buying:   vhigh, high, med, low.\\nmaint:    vhigh, high, med, low.\\ndoors:    2, 3, 4, 5more.\\npersons:  2, 4, more.\\nlug_boot: small, med, big.\\nsafety:   low, med, high.', 'citation': None}}\n",
      "       name     role         type demographic  \\\n",
      "0    buying  Feature  Categorical        None   \n",
      "1     maint  Feature  Categorical        None   \n",
      "2     doors  Feature  Categorical        None   \n",
      "3   persons  Feature  Categorical        None   \n",
      "4  lug_boot  Feature  Categorical        None   \n",
      "5    safety  Feature  Categorical        None   \n",
      "6     class   Target  Categorical        None   \n",
      "\n",
      "                                         description units missing_values  \n",
      "0                                       buying price  None             no  \n",
      "1                           price of the maintenance  None             no  \n",
      "2                                    number of doors  None             no  \n",
      "3              capacity in terms of persons to carry  None             no  \n",
      "4                           the size of luggage boot  None             no  \n",
      "5                        estimated safety of the car  None             no  \n",
      "6  evaulation level (unacceptable, acceptable, go...  None             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "car_evaluation = fetch_ucirepo(id=19) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X_2 = car_evaluation.data.features \n",
    "y_2 = car_evaluation.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(car_evaluation.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(car_evaluation.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c1e0ee7-2432-4261-90e6-25627b21770b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  buying  maint doors persons lug_boot safety\n",
      "0  vhigh  vhigh     2       2    small    low\n",
      "1  vhigh  vhigh     2       2    small    med\n",
      "2  vhigh  vhigh     2       2    small   high\n",
      "3  vhigh  vhigh     2       2      med    low\n",
      "4  vhigh  vhigh     2       2      med    med\n",
      "   class\n",
      "0  unacc\n",
      "1  unacc\n",
      "2  unacc\n",
      "3  unacc\n",
      "4  unacc\n"
     ]
    }
   ],
   "source": [
    "print(X_2.head())\n",
    "print(y_2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51265ca1-7a12-4d39-9223-d152f76d5928",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2_binary = y_2.copy()\n",
    "y_2_binary[\"class\"] = y_2_binary[\"class\"].apply(lambda x: 0 if x == \"unacc\" else 1)\n",
    "\n",
    "X_2_encoded = X_2.copy()\n",
    "for col in X_2.columns:\n",
    "    X_2_encoded[col] = LabelEncoder().fit_transform(X_2[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1da0c235-efed-4ee3-94a3-1e035670c8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_2 = {\n",
    "    \"20/80\": train_test_split(X_2_encoded, y_2_binary[\"class\"], train_size=0.2, random_state=42, stratify=y_2_binary[\"class\"]),\n",
    "    \"50/50\": train_test_split(X_2_encoded, y_2_binary[\"class\"], train_size=0.5, random_state=42, stratify=y_2_binary[\"class\"]),\n",
    "    \"80/20\": train_test_split(X_2_encoded, y_2_binary[\"class\"], train_size=0.8, random_state=42, stratify=y_2_binary[\"class\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af028da5-6bf5-41fc-9550-4b7295b49a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_hyperparameters(X_train, y_train, clf_name):\n",
    "    if clf_name == \"Random Forest\":\n",
    "        param_grid = {\"max_depth\": [10, 20, 30]}\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "    elif clf_name == \"SVM\":\n",
    "        param_grid = {\"C\": [0.1, 1, 10, 100]}\n",
    "        model = SVC(kernel=\"rbf\", random_state=42)\n",
    "    elif clf_name == \"Logistic Regression\":\n",
    "        param_grid = {\"C\": [0.1, 1, 10, 100]}\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "    grid = GridSearchCV(model, param_grid, cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    return grid.best_params_\n",
    "\n",
    "best_params_2 = {}\n",
    "\n",
    "for split_name, (X_train, X_test, y_train, y_test) in splits_2.items():\n",
    "    best_params_2[split_name] = {\n",
    "        \"Random Forest\": tune_hyperparameters(X_train, y_train, \"Random Forest\"),\n",
    "        \"SVM\": tune_hyperparameters(X_train, y_train, \"SVM\"),\n",
    "        \"Logistic Regression\": tune_hyperparameters(X_train, y_train, \"Logistic Regression\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1db0496c-150d-4d26-b54f-f73e2e7af442",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_2 = {}\n",
    "val_acc_2 = {}\n",
    "test_acc_2 = {}\n",
    "\n",
    "for split_name, (X_train, X_test, y_train, y_test) in splits_2.items():\n",
    "    rf_params = best_params_2[split_name][\"Random Forest\"]\n",
    "    svm_params = best_params_2[split_name][\"SVM\"]\n",
    "    lr_params = best_params_2[split_name][\"Logistic Regression\"]\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=42, **rf_params)\n",
    "    svm = SVC(random_state=42, **svm_params)\n",
    "    lr = LogisticRegression(random_state=42, max_iter=1000, **lr_params)\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    svm.fit(X_train, y_train)\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    rf_val_acc = cross_val_score(rf, X_train, y_train, cv=3, scoring=\"accuracy\").mean()\n",
    "    svm_val_acc = cross_val_score(svm, X_train, y_train, cv=3, scoring=\"accuracy\").mean()\n",
    "    lr_val_acc = cross_val_score(lr, X_train, y_train, cv=3, scoring=\"accuracy\").mean()\n",
    "\n",
    "    train_acc_2[split_name] = {\n",
    "        \"Random Forest\": accuracy_score(y_train, rf.predict(X_train)),\n",
    "        \"SVM\": accuracy_score(y_train, svm.predict(X_train)),\n",
    "        \"Logistic Regression\": accuracy_score(y_train, lr.predict(X_train)),\n",
    "    }\n",
    "\n",
    "    val_acc_2[split_name] = {\n",
    "        \"Random Forest\": rf_val_acc,\n",
    "        \"SVM\": svm_val_acc,\n",
    "        \"Logistic Regression\": lr_val_acc,\n",
    "    }\n",
    "\n",
    "    test_acc_2[split_name] = {\n",
    "        \"Random Forest\": accuracy_score(y_test, rf.predict(X_test)),\n",
    "        \"SVM\": accuracy_score(y_test, svm.predict(X_test)),\n",
    "        \"Logistic Regression\": accuracy_score(y_test, lr.predict(X_test)),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23a4c46d-0167-4cce-ba06-e415e41c480b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Classifier Train/Test  Training Accuracy  Validation Accuracy  \\\n",
      "0        Random Forest      20/80           1.000000             0.942029   \n",
      "1                  SVM      20/80           0.997101             0.901449   \n",
      "2  Logistic Regression      20/80           0.753623             0.730435   \n",
      "3        Random Forest      50/50           1.000000             0.968750   \n",
      "4                  SVM      50/50           1.000000             0.975694   \n",
      "5  Logistic Regression      50/50           0.717593             0.712963   \n",
      "6        Random Forest      80/20           1.000000             0.987692   \n",
      "7                  SVM      80/20           1.000000             0.992042   \n",
      "8  Logistic Regression      80/20           0.719247             0.711270   \n",
      "\n",
      "   Testing Accuracy Best Hyperparameter  \n",
      "0          0.952278   {'max_depth': 10}  \n",
      "1          0.962401           {'C': 10}  \n",
      "2          0.715835            {'C': 1}  \n",
      "3          0.984954   {'max_depth': 20}  \n",
      "4          0.988426          {'C': 100}  \n",
      "5          0.696759           {'C': 10}  \n",
      "6          0.991329   {'max_depth': 10}  \n",
      "7          1.000000          {'C': 100}  \n",
      "8          0.702312            {'C': 1}  \n"
     ]
    }
   ],
   "source": [
    "results_2 = []\n",
    "\n",
    "for split_name in splits_2.keys():\n",
    "    for clf_name in [\"Random Forest\", \"SVM\", \"Logistic Regression\"]:\n",
    "        results_2.append({\n",
    "            \"Classifier\": clf_name,\n",
    "            \"Train/Test\": split_name,\n",
    "            \"Training Accuracy\": train_acc_2[split_name][clf_name],\n",
    "            \"Validation Accuracy\": val_acc_2[split_name][clf_name],\n",
    "            \"Testing Accuracy\": test_acc_2[split_name][clf_name],\n",
    "            \"Best Hyperparameter\": best_params_2[split_name][clf_name]\n",
    "        })\n",
    "\n",
    "results_df_2 = pd.DataFrame(results_2)\n",
    "\n",
    "print(results_df_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
